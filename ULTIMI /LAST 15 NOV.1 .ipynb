{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a7799b-c42b-45f5-8d6c-7e8d4072191c",
   "metadata": {},
   "source": [
    "<h2>INSTALLAZIONE LIBRERIE</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4853b-1af1-4396-963d-0e29644837df",
   "metadata": {},
   "source": [
    "<p style=\"font-size:14px; font-family:verdana; line-height: 1.7em\">\n",
    "Installazione librerie <strong>necessarie per il funzionamento</strong> del progetto:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428c71d-b081-429a-b552-46290fd2e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --quiet --upgrade pip scipy matplotlib wordcloud seaborn nltk scikit-learn plotly nbformat imbalanced-learn tqdm xgboost pillow tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8988a-f4b1-4551-ba52-cd7389defa9c",
   "metadata": {},
   "source": [
    "<h2>IMPORTAZIONE LIBRERIE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d4c7f-550a-4a09-80a6-828adb084864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo e manipolazione dati\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "# Visualizzazione\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "# NLP e Preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from collections import Counter\n",
    "\n",
    "# Gestione degli squilibri di classe\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Machine Learning e Modelli\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Metriche di valutazione\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay, log_loss, precision_recall_fscore_support, classification_report, accuracy_score, f1_score)\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Utility\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm  # Barra di avanzamento\n",
    "import time\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignorare avvisi\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1b383-df5c-46ec-b763-c8dd5253cc2f",
   "metadata": {},
   "source": [
    "<h2>ESPLORAZIONE DEI DATI (EDA)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd586d9-21d6-4245-9b02-c475ed8c1089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento Dataset\n",
    "training_variants = pd.read_csv(\"/Users/diego/Desktop/TIROCINIO/DATASET/training_variants.csv\")\n",
    "training_text = pd.read_csv(\"/Users/diego/Desktop/TIROCINIO/DATASET/training_text.csv\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=['ID','text'])\n",
    "\n",
    "# Stampa strutturata dei dati\n",
    "print(f\"{'\\nDataset':<20}{'(Righe, Colonne)':<30}\")\n",
    "print(f\"{'-'*50}\")\n",
    "print(f\"{'Training variants':<20}{str(training_variants.shape):<30}\")\n",
    "print(f\"{'Training text':<20}{str(training_text.shape):<30}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201435e6-2e24-45f5-8312-3851903413d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unione varianti e testo di addestramento \n",
    "df = pd.merge(training_variants, training_text, on = 'ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4b30d-f449-498c-b9ce-b005ae48d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta i valori delle classi e li ordina\n",
    "plot_dist = df['Class'].value_counts().sort_index()\n",
    "\n",
    "# Crea il grafico a barre\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Crea le barre\n",
    "bars = ax.bar(plot_dist.index, plot_dist.values)\n",
    "\n",
    "# Aggiungi il titolo e le etichette\n",
    "ax.set_title('Distribuzione di frequenza per tutte le classi', loc='center', pad=20)\n",
    "ax.set_xlabel('Classe')\n",
    "ax.set_ylabel('Frequenza')\n",
    "\n",
    "# Aggiungi i valori sopra le barre\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval, yval, va='bottom', ha='center', fontsize=12)\n",
    "\n",
    "# Imposta il limite massimo dell'asse y a 1200\n",
    "ax.set_ylim(0, 1200)\n",
    "\n",
    "\n",
    "# Imposta i tick dell'asse x per tutte le classi\n",
    "ax.set_xticks(range(0, 10))  # Imposta tick per ogni classe\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164af99-0a21-47c0-9234-b0048583b8cd",
   "metadata": {},
   "source": [
    "<h2>PRE-ELABORAZIONE DEL TESTO</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7f16a-715c-4ec1-9d78-64c767fd22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Inserimento di altre stop words manualmente adatte al contesto\n",
    "custom_words = [\"fig\", \"figure\", \"et\", \"al\", \"al.\", \"also\", \"data\", \"analyze\", \"study\", \n",
    "                \"table\", \"using\", \"method\", \"result\", \"conclusion\", \"author\", \"find\", \"found\", \"show\"]\n",
    "\n",
    "# Unione delle stop words di default + la punteggiatura + quelle aggiunte manualmente \n",
    "stop_words = set(stopwords.words('english') + list(string.punctuation) + custom_words)\n",
    "\n",
    "# Inizializzazione dello stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def pre_process(text):\n",
    "    if isinstance(text, float):\n",
    "        return ''  # Gestione di valori float\n",
    "    \n",
    "    text = str(text).lower().strip()\n",
    "    \n",
    "    # Rimozione di punteggiatura, HTML e caratteri speciali\n",
    "    text = re.sub(f'[{re.escape(string.punctuation)}]', ' ', text)\n",
    "    text = re.sub(r'<.*?>+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Tokenizzazione, rimozione stopwords e stemming\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [\n",
    "        stemmer.stem(word) for word in tokens \n",
    "        if word not in stop_words and not word.isdigit() and len(word) > 1  # ignora parole di lunghezza 1\n",
    "    ]\n",
    "    \n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "\n",
    "def process_corpus(df, text_column, class_column):\n",
    "    return df.groupby(class_column).apply(lambda x: Counter(word_tokenize(pre_process(x[text_column].str.cat(sep=' ')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3ecab-41a5-4bcf-9056-475a8af7b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing dei dati con barra di avanzamento\n",
    "print(\"Preprocessing dei dati...\")\n",
    "df['text'] = [pre_process(text) for text in tqdm(df['text'], desc=\"Preprocessing\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d85cfb-b805-4894-bafd-78eff06eab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f50fb-95be-4e5d-8734-ff3f0b434d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerchiamo righe con valori nulli o con la colonna 'text' vuota\n",
    "df[df.isnull().any(axis=1) | (df['text'] == '')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a2199-1ec4-4777-96c1-5dbe4403147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina righe con valori nulli o con campo 'text' vuoto\n",
    "df = df.dropna(subset=[\"text\"]).loc[df['text'] != '']\n",
    "\n",
    "# Cerchiamo nuovamente righe con valori nulli o con la colonna 'text' vuota\n",
    "df[df.isnull().any(axis=1) | (df['text'] == '')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493be7ee-9b5a-4688-bffe-0850460f654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta i valori delle classi e li ordina\n",
    "plot_dist = df['Class'].value_counts().sort_index()\n",
    "\n",
    "# Crea il grafico a barre\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Crea le barre\n",
    "bars = ax.bar(plot_dist.index, plot_dist.values)\n",
    "\n",
    "# Aggiungi il titolo e le etichette\n",
    "ax.set_title('Distribuzione di frequenza per tutte le classi', loc='center', pad=20)\n",
    "ax.set_xlabel('Classe')\n",
    "ax.set_ylabel('Frequenza')\n",
    "\n",
    "# Aggiungi i valori sopra le barre\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval, yval, va='bottom', ha='center', fontsize=12)\n",
    "\n",
    "# Imposta il limite massimo dell'asse y a 1200\n",
    "ax.set_ylim(0, 1200)\n",
    "\n",
    "\n",
    "# Imposta i tick dell'asse x per tutte le classi\n",
    "ax.set_xticks(range(0, 10))  # Imposta tick per ogni classe\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef30934-c3eb-4d52-b4d3-0347e5b7ed81",
   "metadata": {},
   "source": [
    "<h2>ANALISI DELLE FEATURES:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822be75e-38e5-49f0-9327-23bbc731e44d",
   "metadata": {},
   "source": [
    "<h3> - GENI</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e6fe7-577d-4e08-8c80-479bbb892e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genes = df['Gene'].value_counts()\n",
    "\n",
    "# Stampa del numero di geni unici\n",
    "print('Numero di Geni Unici:', unique_genes.shape[0])\n",
    "print(' ')\n",
    "# Stampa dei top 5 geni più frequenti \n",
    "print(\"Top 5 Geni più frequenti:\")\n",
    "print(' ')\n",
    "for gene, count in unique_genes.head(5).items():\n",
    "    print(f'{gene}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad26505-c9c3-4c4b-afbb-4130d1d8315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione dei sottotitoli per il grafico\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, sharey=True, figsize=(9, 9))\n",
    "\n",
    "# Normalizzazione dei conteggi per una migliore comparazione\n",
    "def normalize_group(x):\n",
    "    label, repetition = x.index, x\n",
    "    t = sum(repetition)\n",
    "    r = [n/t for n in repetition]\n",
    "    return label, r\n",
    "\n",
    "# Creazione dei grafici per ogni classe\n",
    "for idx, g in enumerate(df.groupby('Class')):\n",
    "    label, val = normalize_group(g[1][\"Gene\"].value_counts())\n",
    "    ax = axes.flat[idx]\n",
    "    ax.bar(np.arange(5), val[:5], tick_label=label[:5]) \n",
    "    ax.set_title(\"Classe {}\".format(g[0]))\n",
    "\n",
    "# Etichette\n",
    "fig.text(0.5, 0.97, '(Top 5) Frequenza dei Geni per Classe', ha='center', fontsize=14, fontweight='bold')\n",
    "fig.text(0.5, 0, 'Gene', ha='center', fontweight='bold')\n",
    "fig.text(0, 0.5, 'Frequenza', va='center', rotation='vertical', fontweight='bold')\n",
    "\n",
    "# Ottimizzazione del layout\n",
    "fig.tight_layout(rect=[0.03, 0.03, 0.95, 0.95])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d712c-8b03-4f0c-be75-517c7c152259",
   "metadata": {},
   "source": [
    "<h3> - VARIANTI</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3dab3-2783-4063-8697-05bc89eef713",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_variations = df['Variation'].value_counts()\n",
    "\n",
    "# Stampa del numero di Varianti uniche\n",
    "print('Numero di Varianti Uniche:', unique_variations.shape[0])\n",
    "print(' ')\n",
    "\n",
    "# Stampa delle top 10 Varianti più frequenti senza \"name\" e \"dtype\"\n",
    "print(\"Top 5 Varianti più frequenti:\")\n",
    "print(' ')\n",
    "for variation, count in unique_variations.head(10).items():\n",
    "    print(f'{variation}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7f399-5247-4624-9ae4-9da5ea4fe740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta i valori delle varianti e prendi solo le prime 10 più frequenti\n",
    "variations_data = df['Variation'].value_counts().head(10)\n",
    "\n",
    "# Crea il grafico a barre\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Crea le barre\n",
    "bars = ax.bar(variations_data.index, variations_data.values)\n",
    "\n",
    "# Aggiungi il titolo e le etichette\n",
    "ax.set_title('Distribuzione delle 10 varianti più frequenti', loc='center', pad=20)\n",
    "ax.set_xlabel('Variante')  # Titolo dell'asse x\n",
    "ax.set_ylabel('Frequenza')  # Titolo dell'asse y\n",
    "\n",
    "# Aggiungi i valori sopra le barre\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval, yval, va='bottom', ha='center', fontsize=12)\n",
    "\n",
    "# Imposta il limite dell'asse y e i tick\n",
    "ax.set_ylim(0, 120)  # Imposta il limite massimo dell'asse y a 120\n",
    "ax.set_yticks(range(0, 121, 20))  # Imposta i tick dell'asse y da 0 a 120, con intervallo di 20\n",
    "\n",
    "# Personalizzazione del font\n",
    "plt.xticks(rotation=45, ha='right')  # Ruota le etichette dell'asse x se necessario\n",
    "plt.subplots_adjust(bottom=0.2)  # Aggiungi spazio in basso se le etichette sono lunghe\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a25d1-de9c-404d-95bb-229cc1d52d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unione di tutto il testo in una singola stringa\n",
    "all_text = ' '.join(df['text'].dropna())\n",
    "\n",
    "# Tokenizzazione del testo e conteggio delle parole\n",
    "tokens = all_text.split()  # Dividi il testo in parole\n",
    "word_counts = Counter(tokens)  # Conta la frequenza di ogni parola\n",
    "\n",
    "# Converti il conteggio delle parole in un DataFrame ordinato\n",
    "word_freq_df = pd.DataFrame(word_counts.items(), columns=['word', 'frequency']).sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Filtra per le parole più frequenti (ad esempio le prime 20)\n",
    "top_words_df = word_freq_df.head(20)\n",
    "\n",
    "# Crea il grafico delle parole ordinate per frequenza\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top_words_df, y='word', x='frequency', palette='viridis')\n",
    "plt.xlabel('Frequenza')\n",
    "plt.ylabel('Parola')\n",
    "plt.title('Parole più frequenti nel dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974519a7-db6b-437d-86d0-e3019362f478",
   "metadata": {},
   "source": [
    "<h2> MODELLAZIONE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1563fc-8077-445b-bf12-0e1b18e3e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separazione delle feature e del target\n",
    "X = df['text']\n",
    "y = df['Class']\n",
    "\n",
    "# Funzione per ottenere i modelli\n",
    "def get_models():\n",
    "    models = {\n",
    "        \"RF\": RandomForestClassifier(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"LR\": LogisticRegression(),\n",
    "        \"XGBoost\": XGBClassifier()\n",
    "    }\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5ffdf-3ac5-41d9-872d-e7d80ef642f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle griglie di parametri per i modelli\n",
    "def get_param_grids():\n",
    "    param_grids = {\n",
    "        \"RF\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [10, 20, 30, None],\n",
    "        },\n",
    "        \n",
    "        \"KNN\": {\n",
    "            \"n_neighbors\": [3, 5, 7],\n",
    "            \"weights\": ['uniform', 'distance'],\n",
    "        },\n",
    "        \n",
    "        \"LR\": {},\n",
    "        \n",
    "        \"XGBoost\": {\n",
    "            \"learning_rate\": [0.1], \n",
    "            \"n_estimators\": [50, 100, 150],\n",
    "            \"max_depth\": [3, 6, 9],\n",
    "        }\n",
    "    }\n",
    "    return param_grids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9decd838-c06b-4aaf-aac0-83e26cdf623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione GridSearch con Cross Validazione\n",
    "def perform_grid_search(model, X_train, y_train, param_grid):\n",
    "    # GridSearch con Cross-Validation\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1, verbose=0)\n",
    "    \n",
    "    # Fitting del modello\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Migliori parametri trovati\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    return best_model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d3adb-5ee8-41d2-a9c3-ad0bcbc03f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per valutare il modello\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Predizioni\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return precision, recall, f1, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247087ab-f451-4eb7-8eeb-e48f24cbb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(y_train, y_test, title_train=\"Distribuzione classi Train\", title_test=\"Distribuzione classi Test\"):\n",
    "    # Conta le frequenze delle classi\n",
    "    train_dist = np.unique(y_train, return_counts=True)\n",
    "    test_dist = np.unique(y_test, return_counts=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Grafico per il dataset di training\n",
    "    bars_train = axes[0].bar(train_dist[0], train_dist[1], color='blue', alpha=0.7)\n",
    "    axes[0].set_title(title_train, loc='center', pad=20)\n",
    "    axes[0].set_xlabel('Classi')\n",
    "    axes[0].set_ylabel('Frequenza')\n",
    "\n",
    "    # Aggiungi i valori sopra le barre\n",
    "    for bar in bars_train:\n",
    "        yval = bar.get_height()\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2, yval, int(yval), va='bottom', ha='center', fontsize=10)\n",
    "    \n",
    "    # Grafico per il dataset di test\n",
    "    bars_test = axes[1].bar(test_dist[0], test_dist[1], color='green', alpha=0.7)\n",
    "    axes[1].set_title(title_test, loc='center', pad=20)\n",
    "    axes[1].set_xlabel('Classi')\n",
    "    axes[1].set_ylabel('Frequenza')\n",
    "\n",
    "    # Aggiungi i valori sopra le barre\n",
    "    for bar in bars_test:\n",
    "        yval = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2, yval, int(yval), va='bottom', ha='center', fontsize=10)\n",
    "\n",
    "    # Ottimizza il layout e mostra i grafici\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec7169-1d06-469f-8754-2c0ab0188c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset originario diviso in (80/20) train e test con TF-IDF e SVD\n",
    "def process_original_dataset(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    tfidf = TfidfVectorizer(max_features=1000)\n",
    "    svd = TruncatedSVD(n_components=100)\n",
    "    \n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "    X_test_svd = svd.transform(X_test_tfidf)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_svd)\n",
    "    X_test_scaled = scaler.transform(X_test_svd)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "# Dataset originario diviso in (80/20) train e test con TF-IDF e SVD\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = process_original_dataset(X, y)\n",
    "\n",
    "# Generazione dei grafici per la distribuzione delle classi\n",
    "plot_class_distribution(y_train, y_test, title_train=\"Distribuzione classi Train (Originale)\", title_test=\"Distribuzione classi Test (Originale)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d39a1d-5100-4338-8bc7-ada2cce0f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_semibalanced_dataset(X, y):\n",
    "    # Dividi il dataset originario in train e test (80/20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Applica RandomOverSampler per bilanciare le classi nel set di addestramento\n",
    "    ros = RandomOverSampler(sampling_strategy={3: 350, 8: 350, 9: 350}, random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Applica TF-IDF ai dati di train e test\n",
    "    tfidf = TfidfVectorizer(max_features=1000)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train_resampled)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    # Applica SVD al dataset bilanciato\n",
    "    svd = TruncatedSVD(n_components=100)\n",
    "    X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "    X_test_svd = svd.transform(X_test_tfidf)\n",
    "    \n",
    "    # Scala i dati\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_svd)\n",
    "    X_test_scaled = scaler.transform(X_test_svd)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train_resampled, y_test\n",
    "\n",
    "# Esempio di utilizzo della nuova funzione\n",
    "X_train_scaled_balanced, X_test_scaled_balanced, y_train_balanced, y_test_balanced = process_semibalanced_dataset(X, y)\n",
    "\n",
    "# Generazione dei grafici per la distribuzione delle classi\n",
    "plot_class_distribution(y_train_balanced, y_test_balanced, title_train=\"Distribuzione classi Train (Random Over-Sampling)\", title_test=\"Distribuzione classi Test (Originale)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efd6c3-52f2-41db-a800-af64a213a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset bilanciato con RandomOverSampler e poi diviso in (80/20) train, test con TF-IDF e SVD\n",
    "def process_balanced_dataset(X, y):\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X.values.reshape(-1, 1), y)\n",
    "    X_resampled = pd.Series(X_resampled.flatten())\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    tfidf = TfidfVectorizer(max_features=1000)\n",
    "    svd = TruncatedSVD(n_components=100)\n",
    "    \n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "    X_test_svd = svd.transform(X_test_tfidf)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_svd)\n",
    "    X_test_scaled = scaler.transform(X_test_svd)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "# Dataset bilanciato con RandomOverSampler\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = process_balanced_dataset(X, y)\n",
    "\n",
    "# Generazione dei grafici per la distribuzione delle classi\n",
    "plot_class_distribution(y_train, y_test, title_train=\"Distribuzione classi Train (Bilanciato)\", title_test=\"Distribuzione classi Test (Bilanciato)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e0b03-598b-4978-8df2-e2882e2ae4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per addestrare, ottimizzare e testare i modelli su un dataset specifico\n",
    "def train_evaluate_model(model, model_name, X, y, dataset_type):\n",
    "    if dataset_type == \"original\":\n",
    "        X_train, X_test, y_train, y_test = process_original_dataset(X, y)\n",
    "    elif dataset_type == \"semibalanced\":\n",
    "        X_train, X_test, y_train, y_test = process_semibalanced_dataset(X, y)\n",
    "    elif dataset_type == \"balanced\":\n",
    "        X_train, X_test, y_train, y_test = process_balanced_dataset(X, y)\n",
    "      \n",
    "    else:\n",
    "        raise ValueError(\"Dataset non valido per l'addestramento\")\n",
    "    \n",
    "    param_grids = get_param_grids()\n",
    "    \n",
    "    # Se si utilizza XGBoost, codifica le etichette\n",
    "    if model_name == \"XGBoost\":\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train = label_encoder.fit_transform(y_train)\n",
    "        y_test = label_encoder.transform(y_test)\n",
    "    \n",
    "    best_model, best_params = perform_grid_search(model, X_train, y_train, param_grids[model_name])\n",
    "    precision, recall, f1, accuracy = evaluate_model(best_model, X_test, y_test)\n",
    "    \n",
    "    # Arrotonda le metriche a 4 cifre decimali\n",
    "    precision = round(precision, 4)\n",
    "    recall = round(recall, 4)\n",
    "    f1 = round(f1, 4)\n",
    "    accuracy = round(accuracy, 4)\n",
    "    \n",
    "    return [model_name, precision, recall, f1, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a79aa-34f6-4d46-94bf-72cb3cd78b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sezione per il modello RandomForest\n",
    "print(\"Valutazione su set di Test per RandomForest Classifier\")\n",
    "\n",
    "# Valutazione su dataset originale, bilanciato e semibilanciato\n",
    "rf_results_original = [\"Originale\"] + train_evaluate_model(RandomForestClassifier(), \"RF\", X, y, \"original\")\n",
    "rf_results_semibalanced = [\"Semibilanciato\"] + train_evaluate_model(RandomForestClassifier(), \"RF\", X, y, \"semibalanced\")  \n",
    "rf_results_balanced = [\"Bilanciato\"] + train_evaluate_model(RandomForestClassifier(), \"RF\", X, y, \"balanced\")\n",
    "\n",
    "# Raggruppamento dei risultati\n",
    "rf_results = [rf_results_original, rf_results_semibalanced, rf_results_balanced]\n",
    "\n",
    "# Intestazioni della tabella\n",
    "headers = [\"Dataset\", \"Model\", \"Precision\", \"Recall\", \"F1 Score\", \"Accuracy\"]\n",
    "\n",
    "# Stampa della tabella con i risultati\n",
    "print(tabulate(rf_results, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f823eec-1bc1-46d9-bbd9-974329262c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Calcolo delle matrici di confusione ---\n",
    "\n",
    "# Funzione per ottenere il miglior modello da train_evaluate_model\n",
    "def get_best_model_and_data(X, y, dataset_type):\n",
    "    if dataset_type == \"original\":\n",
    "        X_train, X_test, y_train, y_test = process_original_dataset(X, y)\n",
    "    elif dataset_type == \"semibalanced\":\n",
    "        X_train, X_test, y_train, y_test = process_semibalanced_dataset(X, y)\n",
    "    elif dataset_type == \"balanced\":\n",
    "        X_train, X_test, y_train, y_test = process_balanced_dataset(X, y)\n",
    "    else:\n",
    "        raise ValueError(\"Dataset non valido per l'addestramento\")\n",
    "    \n",
    "    # Ottieni il miglior modello dalla funzione di grid search\n",
    "    model = RandomForestClassifier()\n",
    "    param_grids = get_param_grids()\n",
    "    best_model, best_params = perform_grid_search(model, X_train, y_train, param_grids[\"RF\"])\n",
    "    \n",
    "    return best_model, X_test, y_test\n",
    "\n",
    "# Ottieni il miglior modello e i dati per ogni dataset\n",
    "best_model_original_rf, X_test_original, y_test_original = get_best_model_and_data(X, y, \"original\")\n",
    "best_model_semibalanced_rf, X_test_semibalanced, y_test_semibalanced = get_best_model_and_data(X, y, \"semibalanced\")\n",
    "best_model_balanced_rf, X_test_balanced, y_test_balanced = get_best_model_and_data(X, y, \"balanced\")\n",
    "\n",
    "# Fai le previsioni\n",
    "y_pred_original_rf = best_model_original_rf.predict(X_test_original)\n",
    "y_pred_semibalanced_rf = best_model_semibalanced_rf.predict(X_test_semibalanced)\n",
    "y_pred_balanced_rf = best_model_balanced_rf.predict(X_test_balanced)\n",
    "\n",
    "# Calcola le matrici di confusione\n",
    "cm_original_rf = confusion_matrix(y_test_original, y_pred_original_rf)\n",
    "cm_semibalanced_rf = confusion_matrix(y_test_semibalanced, y_pred_semibalanced_rf)\n",
    "cm_balanced_rf = confusion_matrix(y_test_balanced, y_pred_balanced_rf)\n",
    "\n",
    "# Imposta il grafico\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Disegna la matrice di confusione per il dataset originale\n",
    "sns.heatmap(cm_original_rf, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0], cbar=False)\n",
    "axes[0].set_title(\"Matrice di Confusione - Originale\")\n",
    "axes[0].set_xlabel(\"Predizione\")\n",
    "axes[0].set_ylabel(\"Reale\")\n",
    "\n",
    "# Disegna la matrice di confusione per il dataset semibilanciato\n",
    "sns.heatmap(cm_semibalanced_rf, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[1], cbar=False)\n",
    "axes[1].set_title(\"Matrice di Confusione - Semibilanciato\")\n",
    "axes[1].set_xlabel(\"Predizione\")\n",
    "axes[1].set_ylabel(\"Reale\")\n",
    "\n",
    "# Disegna la matrice di confusione per il dataset bilanciato\n",
    "sns.heatmap(cm_balanced_rf, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[2], cbar=False)\n",
    "axes[2].set_title(\"Matrice di Confusione - Bilanciato\")\n",
    "axes[2].set_xlabel(\"Predizione\")\n",
    "axes[2].set_ylabel(\"Reale\")\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76874dcb-bf66-4968-b761-4ea193bd636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sezione per il modello KNeighbors\n",
    "print(\"\\nValutazione su set di Test per KNeighbors Classifier\")\n",
    "\n",
    "# Valutazione su dataset originale, bilanciato e semibilanciato\n",
    "knn_results_original = [\"Originale\"] + train_evaluate_model(KNeighborsClassifier(), \"KNN\", X, y, \"original\")\n",
    "knn_results_semibalanced = [\"Semibilanciato\"] + train_evaluate_model(KNeighborsClassifier(), \"KNN\", X, y, \"semibalanced\") \n",
    "knn_results_balanced = [\"Bilanciato\"] + train_evaluate_model(KNeighborsClassifier(), \"KNN\", X, y, \"balanced\")\n",
    "\n",
    "# Raggruppamento dei risultati\n",
    "knn_results = [knn_results_original, knn_results_semibalanced, knn_results_balanced]\n",
    "\n",
    "# Intestazioni della tabella\n",
    "headers = [\"Dataset\", \"Model\", \"Precision\", \"Recall\", \"F1 Score\", \"Accuracy\"]\n",
    "\n",
    "# Stampa della tabella con i risultati\n",
    "print(tabulate(knn_results, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b7d5a-efcc-46c2-bf58-59e8ad0c6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sezione per il modello LogisticRegression\n",
    "print(\"\\nValutazione su set di Test per LogisticRegression Classifier\")\n",
    "\n",
    "# Valutazione su dataset originale, bilanciato e semibilanciato\n",
    "lr_results_original = [\"Originale\"] + train_evaluate_model(LogisticRegression(max_iter=500), \"LR\", X, y, \"original\")\n",
    "lr_results_semibalanced = [\"Semibilanciato\"] + train_evaluate_model(LogisticRegression(), \"LR\", X, y, \"semibalanced\")\n",
    "lr_results_balanced = [\"Bilanciato\"] + train_evaluate_model(LogisticRegression(), \"LR\", X, y, \"balanced\")\n",
    "\n",
    "# Raggruppamento dei risultati\n",
    "lr_results = [lr_results_original, lr_results_semibalanced, lr_results_balanced]\n",
    "\n",
    "# Intestazioni della tabella\n",
    "headers = [\"Dataset\", \"Model\", \"Precision\", \"Recall\", \"F1 Score\", \"Accuracy\"]\n",
    "\n",
    "# Stampa della tabella con i risultati\n",
    "print(tabulate(lr_results, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd6fd0-0b90-450b-8663-f8b8dcc4c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sezione per il modello XGBoost\n",
    "print(\"\\nValutazione su set di Test per XGBoost Classifier\")\n",
    "\n",
    "# Valutazione su dataset originale, bilanciato e semibilanciato\n",
    "xgb_results_original = [\"Originale\"] + train_evaluate_model(XGBClassifier(), \"XGBoost\", X, y, \"original\")\n",
    "xgb_results_semibalanced = [\"Semibilanciato\"] + train_evaluate_model(XGBClassifier(), \"XGBoost\", X, y, \"semibalanced\") \n",
    "xgb_results_balanced = [\"Bilanciato\"] + train_evaluate_model(XGBClassifier(), \"XGBoost\", X, y, \"balanced\")\n",
    "\n",
    "# Raggruppamento dei risultati\n",
    "xgb_results = [xgb_results_original, xgb_results_semibalanced, xgb_results_balanced]\n",
    "\n",
    "# Intestazioni della tabella\n",
    "headers = [\"Dataset\", \"Model\", \"Precision\", \"Recall\", \"F1 Score\", \"Accuracy\"]\n",
    "\n",
    "# Stampa della tabella con i risultati\n",
    "print(tabulate(xgb_results, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f0dbbb-8c5f-4703-9757-a64a43d22cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per evidenziare il valore migliore in grassetto\n",
    "def bold_best_f1(results, metric_index):\n",
    "    # Filtrare solo i valori numerici per evitare problemi di confronto con stringhe\n",
    "    numeric_results = [row[metric_index] for row in results if isinstance(row[metric_index], (int, float))]\n",
    "    \n",
    "    # Identificare il miglior valore di F1\n",
    "    best_value = max(numeric_results)\n",
    "    \n",
    "    # Evidenziare in grassetto il miglior valore di F1\n",
    "    for i in range(len(results)):\n",
    "        if isinstance(results[i][metric_index], (int, float)) and results[i][metric_index] == best_value:\n",
    "            results[i][metric_index] = f\"\\033[1m{best_value}\\033[0m\"\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Lista dei risultati per il dataset non bilanciato\n",
    "original_results = [\n",
    "    rf_results_original,\n",
    "    knn_results_original,\n",
    "    lr_results_original,\n",
    "    xgb_results_original\n",
    "]\n",
    "\n",
    "# Lista dei risultati per il dataset bilanciato\n",
    "balanced_results = [\n",
    "    rf_results_balanced,\n",
    "    knn_results_balanced,\n",
    "    lr_results_balanced,\n",
    "    xgb_results_balanced\n",
    "]\n",
    "\n",
    "# Lista dei risultati per il dataset semibilanciato\n",
    "semibalanced_results = [\n",
    "    rf_results_semibalanced,\n",
    "    knn_results_semibalanced,\n",
    "    lr_results_semibalanced,\n",
    "    xgb_results_semibalanced\n",
    "]\n",
    "\n",
    "# Evidenzia il miglior F1-Score per il dataset non bilanciato\n",
    "original_results = bold_best_f1(original_results, 4)  # Modificato l'indice a 4 per F1-score\n",
    "\n",
    "# Evidenzia il miglior F1-Score per il dataset bilanciato\n",
    "balanced_results = bold_best_f1(balanced_results, 4)  # Modificato l'indice a 4 per F1-score\n",
    "\n",
    "# Evidenzia il miglior F1-Score per il dataset semibilanciato\n",
    "semibalanced_results = bold_best_f1(semibalanced_results, 4)  # Modificato l'indice a 4 per F1-score\n",
    "\n",
    "# Stampa la tabella per il dataset non bilanciato\n",
    "print(\"\\nValutazioni su Dataset Non Bilanciato\")\n",
    "headers = [\"Dataset\", \"Model\", \"Precision\", \"Recall\", \"F1 Score\", \"Accuracy\"]\n",
    "print(tabulate(original_results, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Stampa la tabella per il dataset semibilanciato\n",
    "print(\"\\nValutazioni su Dataset Semibilanciato\")\n",
    "print(tabulate(semibalanced_results, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Stampa la tabella per il dataset bilanciato\n",
    "print(\"\\nValutazioni su Dataset Bilanciato\")\n",
    "print(tabulate(balanced_results, headers=headers, tablefmt=\"grid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f856c-a261-490f-bdcb-a8ac54945135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
